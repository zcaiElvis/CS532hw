Running deterministic tests
Test 1 starting
Evaluation scheme: desugar
Test 1 passed
Test 2 starting
Evaluation scheme: desugar
Test 2 passed
Test 3 starting
Evaluation scheme: desugar
Test 3 passed
Test 4 starting
Evaluation scheme: desugar
Test 4 passed
Test 5 starting
Evaluation scheme: desugar
Test 5 passed
Test 6 starting
Evaluation scheme: desugar
Test 6 passed
Test 7 starting
Evaluation scheme: desugar
Test 7 passed
Test 8 starting
Evaluation scheme: desugar
Test 8 passed
Test 9 starting
Evaluation scheme: desugar
Test 9 passed
Test 10 starting
Evaluation scheme: desugar
Test 10 passed
Test 11 starting
Evaluation scheme: desugar
Test 11 passed
Test 12 starting
Evaluation scheme: desugar
Test 12 passed
Test 13 starting
Evaluation scheme: desugar
Test 13 passed
Test 14 starting
Evaluation scheme: desugar
Test 14 passed
Test 15 starting
Evaluation scheme: desugar
Test 15 passed
Test 16 starting
Evaluation scheme: desugar
Test 16 passed
Test 17 starting
Evaluation scheme: desugar
Test 17 passed
Test 18 starting
Evaluation scheme: desugar
Test 18 passed
Test 19 starting
Evaluation scheme: desugar
Test 19 passed
Test 20 starting
Evaluation scheme: desugar
Test 20 passed
Test 21 starting
Evaluation scheme: desugar
Test 21 passed
All deterministic tests passed
Running probabilistic tests
Test 1 starting
Evaluation scheme: desugar
Truth: ('normal', 5, 1.4142136)
p value: 0.7418281057328024
Test 1 passed
Test 2 starting
Evaluation scheme: desugar
Truth: ('beta', 2.0, 5.0)
p value: 0.5647495953289097
Test 2 passed
Test 3 starting
Evaluation scheme: desugar
Truth: ('exponential', 0.0, 5.0)
p value: 0.2489022517047419
Test 3 passed
Test 4 starting
Evaluation scheme: desugar
Truth: ('normal', 5.3, 3.2)
p value: 0.3107012099857217
Test 4 passed
Test 5 starting
Evaluation scheme: desugar
Truth: ('normalmix', 0.1, -1, 0.3, 0.9, 1, 0.3)
p value: 0.012936191255694783
Test 5 passed
Test 6 starting
Evaluation scheme: desugar
Truth: ('normal', 0, 1.44)
p value: 0.0894271151024113
Test 6 passed
Test 7 starting
Evaluation scheme: desugar
Truth: ('normal', 0, 1.4142136)
p value: 0.2044752457839748
Test 7 passed
Test 8 starting
Evaluation scheme: desugar
/Users/elvis/Desktop/School/2022/cpsc_536/CPSC532W_hw2/evaluation_based_sampling.py:39: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  sigma+= tc.tensor(logp)
Truth: ('normal', 0, 1)
p value: 0.550509267263807
Test 8 passed
All probabilistic tests passed
Running: HW2: 1
Maximum samples [log10]: 3.0
Maximum time [s]: None
Evaluation scheme: desugar
Samples shape: torch.Size([1000])
First sample: tensor(1.9321)
Sample mean: tensor(0.9774)
Sample standard deviation: tensor(2.3013)
Time taken [s]: 0.7245211601257324
Number of samples: 1000
Finished program 1
Running: HW2: 2
Maximum samples [log10]: 3.0
Maximum time [s]: None
Evaluation scheme: desugar
Samples shape: torch.Size([1000, 2])
First sample: tensor([-10.2244,  -0.6167])
Sample mean: tensor([-0.1586,  0.0727])
Sample standard deviation: tensor([ 9.7697, 10.0922])
[34m[1mwandb[39m[22m: [33mWARNING[39m wandb.plots.* functions are deprecated and will be removed in a future release. Please use wandb.plot.* instead.
Error executing job with overrides: []
Traceback (most recent call last):
  File "/Users/elvis/Desktop/School/2022/cpsc_536/CPSC532W_hw2/run.py", line 126, in run_all
    run_programs(programs, mode=mode, prog_set='HW2', base_dir=base_dir, daphne_dir=daphne_dir, num_samples=num_samples,
  File "/Users/elvis/Desktop/School/2022/cpsc_536/CPSC532W_hw2/run.py", line 93, in run_programs
    if wandb_run: wandb_plots(samples, i)
  File "/Users/elvis/Desktop/School/2022/cpsc_536/CPSC532W_hw2/utils.py", line 44, in wandb_plots
    wandb_log['Program 3; heatmap'] = wandb.plots.HeatMap(xlabels, ylabels, matrix.T, show_text=True)
  File "/Users/elvis/opt/anaconda3/lib/python3.9/site-packages/wandb/plots/heatmap.py", line 43, in heatmap
    if test_missing(
  File "/Users/elvis/opt/anaconda3/lib/python3.9/site-packages/wandb/plots/utils.py", line 21, in test_missing
    pd = util.get_module("pandas", required="Logging dataframes requires pandas")
  File "/Users/elvis/opt/anaconda3/lib/python3.9/site-packages/wandb/util.py", line 317, in get_module
    raise wandb.Error(required)
wandb.errors.Error: Logging dataframes requires pandas
Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.
Time taken [s]: 1.26910400390625
Number of samples: 1000
Finished program 2
Running: HW2: 3
Maximum samples [log10]: 3.0
Maximum time [s]: None
Evaluation scheme: desugar
Samples shape: torch.Size([1000, 17])
First sample: tensor([1., 1., 2., 1., 0., 2., 2., 2., 0., 1., 2., 2., 2., 2., 2., 2., 2.])
Sample mean: tensor([0.9960, 1.3880, 1.4600, 1.4400, 1.4980, 1.5060, 1.4400, 1.4630, 1.4730,
        1.4610, 1.4830, 1.4650, 1.4520, 1.4770, 1.4860, 1.4720, 1.5120])
Sample standard deviation: tensor([0.8128, 0.7416, 0.7556, 0.7688, 0.7500, 0.7201, 0.7635, 0.7571, 0.7549,
        0.7583, 0.7565, 0.7585, 0.7485, 0.7457, 0.7446, 0.7509, 0.7130])